{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to LiveSync docs \u00b6 Note: This site is still draft. please wait for a while. TERMS Introduction What is the database How database and storage are synchronised How to setup the server for trial About Self-hosted LiveSync \u00b6 What we can? \u00b6 By less amount of traffic , usually only metadata and diffs are transfered. Synchronise files between devices . In Live . Or in periodic . Can be combined . Conflict resolution . Showing history and difference, back to the point if you want . End-to-end-encryption is available . Obsidian's configurations and plug-ins also can be synchronised(Experimental) . About filesystem LiveSync \u00b6 To be written About LiveSync-classroom \u00b6 To be written About vorotamoroz \u00b6 If you have interest...","title":"Welcome to LiveSync docs"},{"location":"#welcome-to-livesync-docs","text":"Note: This site is still draft. please wait for a while. TERMS Introduction What is the database How database and storage are synchronised How to setup the server for trial","title":"Welcome to LiveSync docs"},{"location":"#about-self-hosted-livesync","text":"","title":"About Self-hosted LiveSync"},{"location":"#what-we-can","text":"By less amount of traffic , usually only metadata and diffs are transfered. Synchronise files between devices . In Live . Or in periodic . Can be combined . Conflict resolution . Showing history and difference, back to the point if you want . End-to-end-encryption is available . Obsidian's configurations and plug-ins also can be synchronised(Experimental) .","title":"What we can?"},{"location":"#about-filesystem-livesync","text":"To be written","title":"About filesystem LiveSync"},{"location":"#about-livesync-classroom","text":"To be written","title":"About LiveSync-classroom"},{"location":"#about-vorotamoroz","text":"If you have interest...","title":"About vorotamoroz"},{"location":"Conflict%20resolution/","text":"Conflict resolution \u00b6 When some conflicts occur during replication, we can check the differentials and resolve them interactively. Differences will be highlited and timestamps of files will be shown, we can choose which revision to keep, or concat both revision. Of course, we need not to decide immediately. When you choose Not now , This dialog will be shown when we open this file again in any devices.","title":"Conflict resolution"},{"location":"Conflict%20resolution/#conflict-resolution","text":"When some conflicts occur during replication, we can check the differentials and resolve them interactively. Differences will be highlited and timestamps of files will be shown, we can choose which revision to keep, or concat both revision. Of course, we need not to decide immediately. When you choose Not now , This dialog will be shown when we open this file again in any devices.","title":"Conflict resolution"},{"location":"How%20database%20and%20storage%20are%20synchronised/","text":"How database and storage are synchronised? \u00b6 Its based on very simple rule. graph TB A2(Created,Modified)-->B1[Content is same?]; B1-- yes --->X1[\"Skip\"]; B1-- no --->C1[\"Write to the DB\"]; E1[\"Conflict check\"] -- \"Conflicted metadata existed?\" --> F1[\"Conflict resolving\"]; F1 -- \"Auto-resolvable\" --> G1[\"Resolve automatically\"] --> E2; F1 -- \"User decision required\" -->G2[\"Resolving dialog\"] -- something decided --> E2; G2 -- Dismissed --> X2; E2[\"Write back the result(Including update files)\"]-->E1; E1 -- \"Consistent\" ----> X2; X2[\"Completed\"]; A3(Deleted)---->C1; A4[Replication] --> C2[\"DB updated\"]; C2 -- Created --> RD1[\"Create new file\"]; C2 -- Modified or deleted --> RD2[\"Modify\"]; RD2-->E1; subgraph storage event A2 A3 end subgraph Repicational event A4 end Modification will be happen so frequently while we're writing articles, we have the option Batch Database Update . This option queues Write to the DB till switching opened file or replicating. Then we have less changeset. And we can see a document history of write to the DB and DB updated by Show history (While we opening the file) or Pick file to show history .","title":"How database and storage are synchronised?"},{"location":"How%20database%20and%20storage%20are%20synchronised/#how-database-and-storage-are-synchronised","text":"Its based on very simple rule. graph TB A2(Created,Modified)-->B1[Content is same?]; B1-- yes --->X1[\"Skip\"]; B1-- no --->C1[\"Write to the DB\"]; E1[\"Conflict check\"] -- \"Conflicted metadata existed?\" --> F1[\"Conflict resolving\"]; F1 -- \"Auto-resolvable\" --> G1[\"Resolve automatically\"] --> E2; F1 -- \"User decision required\" -->G2[\"Resolving dialog\"] -- something decided --> E2; G2 -- Dismissed --> X2; E2[\"Write back the result(Including update files)\"]-->E1; E1 -- \"Consistent\" ----> X2; X2[\"Completed\"]; A3(Deleted)---->C1; A4[Replication] --> C2[\"DB updated\"]; C2 -- Created --> RD1[\"Create new file\"]; C2 -- Modified or deleted --> RD2[\"Modify\"]; RD2-->E1; subgraph storage event A2 A3 end subgraph Repicational event A4 end Modification will be happen so frequently while we're writing articles, we have the option Batch Database Update . This option queues Write to the DB till switching opened file or replicating. Then we have less changeset. And we can see a document history of write to the DB and DB updated by Show history (While we opening the file) or Pick file to show history .","title":"How database and storage are synchronised?"},{"location":"How%20to%20setup%20the%20server%20for%20trial/","text":"How to setup the server for trial \u00b6 I(vorotamoroz) want to discuss it a little more. Using fly.io is discussed on Main repo Using fly.io \u00b6 Install the CLI ( Docs ) $ curl -L https://fly.io/install.sh | sh or iwr https://fly.io/install.ps1 -useb | iex Sign up (Credit card is required) flyctl auth signup Create the working directory mkdir flyio cd flyio mkdir couchdb cd couchdb Create an app by CouchDB's image flyctl launch --image couchdb Wizard will be launched, answer as you like $ flyctl launch --image couchdb:latest Creating app in ..../flyio/couchdb Using image couchdb:latest ? App Name (leave blank to use an auto-generated name): Automatically selected personal organization: vorotamoroz ? Select region: nrt (Tokyo, Japan) Created app xxxxxx-yyyyyyy-0000 in organization personal Wrote config file fly.toml ? Would you like to setup a Postgresql database now? No ? Would you like to deploy now? No Create data volume fly volumes create --region nrt couchdata --size 2 (This means make 2 GB data volume in the Tokyo region, you have to adjust region you selected) Modify created fly.toml as like below. Please change COUCHDB_USER (I noticed that I snipped instance information lines, please keep these lines) [build] image = \"couchdb:latest\" [env] COUCHDB_USER = \"your_name\" [mounts] source=\"couchdata\" destination=\"/opt/couchdb/data\" [experimental] allowed_public_ports = [] auto_rollback = true [[services]] http_checks = [] internal_port = 5984 processes = [\"app\"] protocol = \"tcp\" script_checks = [] [services.concurrency] hard_limit = 25 soft_limit = 20 type = \"connections\" [[services.ports]] force_https = true handlers = [\"http\"] port = 80 [[services.ports]] handlers = [\"tls\", \"http\"] port = 443 [[services.tcp_checks]] grace_period = \"1s\" interval = \"15s\" restart_limit = 0 timeout = \"2s\" Set your password as you like. flyctl secrets set COUCHDB_PASSWORD=your_password Deploy flyctl deploy Open in browser. flyctl open If you get CouchDB's information, It's ok. Open /_utils, Set up CouchDB (Just hit Configure a Single Node ) https://xxxxxx-yyyyyyy-0000.fly.dev/_utils/#/setup If you have been asked username and password, use COUCHDB_USER and COUCHDB_PASSWORD. Set up Self-hosted LiveSync key value URI https://xxxxxx-yyyyyyy-0000.fly.dev Username COUCHDB_USER Password COUCHDB_PASSWORD Database name anything_you_like Hit the Check database configuration button and Every Fix button. Hit the Test database connection button. If you get Connected to ... , it works! If you suspend the server. you can do this by setting count to 0. (We can run it again with count 1.) fly scale count 0","title":"How to setup the server for trial"},{"location":"How%20to%20setup%20the%20server%20for%20trial/#how-to-setup-the-server-for-trial","text":"I(vorotamoroz) want to discuss it a little more. Using fly.io is discussed on Main repo","title":"How to setup the server for trial"},{"location":"How%20to%20setup%20the%20server%20for%20trial/#using-flyio","text":"Install the CLI ( Docs ) $ curl -L https://fly.io/install.sh | sh or iwr https://fly.io/install.ps1 -useb | iex Sign up (Credit card is required) flyctl auth signup Create the working directory mkdir flyio cd flyio mkdir couchdb cd couchdb Create an app by CouchDB's image flyctl launch --image couchdb Wizard will be launched, answer as you like $ flyctl launch --image couchdb:latest Creating app in ..../flyio/couchdb Using image couchdb:latest ? App Name (leave blank to use an auto-generated name): Automatically selected personal organization: vorotamoroz ? Select region: nrt (Tokyo, Japan) Created app xxxxxx-yyyyyyy-0000 in organization personal Wrote config file fly.toml ? Would you like to setup a Postgresql database now? No ? Would you like to deploy now? No Create data volume fly volumes create --region nrt couchdata --size 2 (This means make 2 GB data volume in the Tokyo region, you have to adjust region you selected) Modify created fly.toml as like below. Please change COUCHDB_USER (I noticed that I snipped instance information lines, please keep these lines) [build] image = \"couchdb:latest\" [env] COUCHDB_USER = \"your_name\" [mounts] source=\"couchdata\" destination=\"/opt/couchdb/data\" [experimental] allowed_public_ports = [] auto_rollback = true [[services]] http_checks = [] internal_port = 5984 processes = [\"app\"] protocol = \"tcp\" script_checks = [] [services.concurrency] hard_limit = 25 soft_limit = 20 type = \"connections\" [[services.ports]] force_https = true handlers = [\"http\"] port = 80 [[services.ports]] handlers = [\"tls\", \"http\"] port = 443 [[services.tcp_checks]] grace_period = \"1s\" interval = \"15s\" restart_limit = 0 timeout = \"2s\" Set your password as you like. flyctl secrets set COUCHDB_PASSWORD=your_password Deploy flyctl deploy Open in browser. flyctl open If you get CouchDB's information, It's ok. Open /_utils, Set up CouchDB (Just hit Configure a Single Node ) https://xxxxxx-yyyyyyy-0000.fly.dev/_utils/#/setup If you have been asked username and password, use COUCHDB_USER and COUCHDB_PASSWORD. Set up Self-hosted LiveSync key value URI https://xxxxxx-yyyyyyy-0000.fly.dev Username COUCHDB_USER Password COUCHDB_PASSWORD Database name anything_you_like Hit the Check database configuration button and Every Fix button. Hit the Test database connection button. If you get Connected to ... , it works! If you suspend the server. you can do this by setting count to 0. (We can run it again with count 1.) fly scale count 0","title":"Using fly.io"},{"location":"Introduction/","text":"Introduction \u00b6 Abstract Initially, this plugin was created for the people with restricted use of the cloud. We use CouchDB for an explicit reason. We are free to say thank you and be polite to the Obsidian and Apache foundation. And thank you! A bit long, but it might be a good narrative. \u00b6 In the beginning, this plugin was made for me, to comply with the regulations that rule traditional companies. So this plugin uses established software stacks for make easier to pass the auditing of server-instaled software source codes. I have been asked to account and responsibility. But I hoped to avoid them by \"Given enough eyeballs\". (\"the Cathedral and the Bazaar\",Raymond, Eric Steven, 1999) This trial works very well, so we will continue not using the software that we should investigate individually (This includes software that I wrote). This means we should to avoid writing any server software and using a non-common protocol if there are no escape-hatch. This is why we use CouchDB. And, We appreciate authors and communities. Especially, Obsidian and CouchDB. (I still sometimes wonder why this plugin has been admitted as a community plugin. All we can do is do our best and be grateful to them. ) Of course, you too. Thank you all. Contributions are always welcome.","title":"Introduction"},{"location":"Introduction/#introduction","text":"Abstract Initially, this plugin was created for the people with restricted use of the cloud. We use CouchDB for an explicit reason. We are free to say thank you and be polite to the Obsidian and Apache foundation. And thank you!","title":"Introduction"},{"location":"Introduction/#a-bit-long-but-it-might-be-a-good-narrative","text":"In the beginning, this plugin was made for me, to comply with the regulations that rule traditional companies. So this plugin uses established software stacks for make easier to pass the auditing of server-instaled software source codes. I have been asked to account and responsibility. But I hoped to avoid them by \"Given enough eyeballs\". (\"the Cathedral and the Bazaar\",Raymond, Eric Steven, 1999) This trial works very well, so we will continue not using the software that we should investigate individually (This includes software that I wrote). This means we should to avoid writing any server software and using a non-common protocol if there are no escape-hatch. This is why we use CouchDB. And, We appreciate authors and communities. Especially, Obsidian and CouchDB. (I still sometimes wonder why this plugin has been admitted as a community plugin. All we can do is do our best and be grateful to them. ) Of course, you too. Thank you all. Contributions are always welcome.","title":"A bit long, but it might be a good narrative."},{"location":"SpecOfSync/","text":"Specification of the synchronisation \u00b6","title":"Specification of the synchronisation"},{"location":"SpecOfSync/#specification-of-the-synchronisation","text":"","title":"Specification of the synchronisation"},{"location":"Synchronise/","text":"Synchronise files between devices \u00b6 LiveSync \u00b6 By using Differential replication , we can synchronise files in the near-real-time. Only we have to enable is LiveSync , we can synchronise in live. Due to its nature, Batch database update cannot be used. This feature will consume more traffic and battery. In mobile device or laptop, we can use Periodic sync alternatively. Periodic sync \u00b6 Enable this option we you want to synchronise regularly. If enabled this option, replication will been started in each configured seconds. What will happen if we don't enable both options? \u00b6 Replication will not run except our interaction or any other synchronise option. Some devices are set to LiveSync, other devices are set to Periodic, and another is set to manual, does it make any trouble? \u00b6 No. This is the ideal configuration. Any other synchronise options \u00b6 Sync on save \u00b6 Synchronise when note has been changed. Changes in other devices will be reflected when we have modified notes. It maybe make us frustrated. Sync on FIle Open \u00b6 Synchronise when note has been changed. Changes in other devices will be reflected when we have opened the note, if we have kept the note be opened, also we be frustrated. Sync on Start \u00b6 Synchronise when Obsidian has been started. Totally fine, when we had enabled all of Any other synchronise options and make sure to shutdown Obsidian after editing on each device. These three options are only recommended in certain situations (i.e., on limited network on a workplace.)","title":"Synchronise files between devices"},{"location":"Synchronise/#synchronise-files-between-devices","text":"","title":"Synchronise files between devices"},{"location":"Synchronise/#livesync","text":"By using Differential replication , we can synchronise files in the near-real-time. Only we have to enable is LiveSync , we can synchronise in live. Due to its nature, Batch database update cannot be used. This feature will consume more traffic and battery. In mobile device or laptop, we can use Periodic sync alternatively.","title":"LiveSync"},{"location":"Synchronise/#periodic-sync","text":"Enable this option we you want to synchronise regularly. If enabled this option, replication will been started in each configured seconds.","title":"Periodic sync"},{"location":"Synchronise/#what-will-happen-if-we-dont-enable-both-options","text":"Replication will not run except our interaction or any other synchronise option.","title":"What will happen if we don't enable both options?"},{"location":"Synchronise/#some-devices-are-set-to-livesync-other-devices-are-set-to-periodic-and-another-is-set-to-manual-does-it-make-any-trouble","text":"No. This is the ideal configuration.","title":"Some devices are set to LiveSync, other devices are set to Periodic, and another is set to manual, does it make any trouble?"},{"location":"Synchronise/#any-other-synchronise-options","text":"","title":"Any other synchronise options"},{"location":"Synchronise/#sync-on-save","text":"Synchronise when note has been changed. Changes in other devices will be reflected when we have modified notes. It maybe make us frustrated.","title":"Sync on save"},{"location":"Synchronise/#sync-on-file-open","text":"Synchronise when note has been changed. Changes in other devices will be reflected when we have opened the note, if we have kept the note be opened, also we be frustrated.","title":"Sync on FIle Open"},{"location":"Synchronise/#sync-on-start","text":"Synchronise when Obsidian has been started. Totally fine, when we had enabled all of Any other synchronise options and make sure to shutdown Obsidian after editing on each device. These three options are only recommended in certain situations (i.e., on limited network on a workplace.)","title":"Sync on Start"},{"location":"TERMS/","text":"..","title":"TERMS"},{"location":"What%20is%20the%20database/","text":"What is the database? \u00b6 LiveSync does not synchronise files directly. All files are synchronised to the local database. At this time, files are separated into two or more entries; the metadata and chunks. We call this as differential replication (I have decided to write this document.) And them will be synchronised between each devices by replicating own local databases to the remote database. graph TB subgraph local[device_A] storage[Storage] <--> localDB[Database]; end subgraph anotherLocal[device_B] anotherStorage[Storage] <--> anotherLocalDB[Database]; end localDB <--> remoteDB[CouchDB]; anotherLocalDB <--> remoteDB; Chunks are key to low-traffic replication and synchronisation. Usually, editable text-file will be split by new-line-mark. ( Details and non-usual cases are here ) Chunks are keyed by its contents, and all metadata has a list of chunk keys as below. graph LR A.md-->A; B.md-->B; C.md-->C; A-->1[\"Willy Wonka, Willy Wonka\"]; A-->2[\"The amazing Chocolatier\"]; A-->1; A-->3[\"Everybody give a cheer!\"]; B-->4[\"Charlie and the Chocolate Factory\"]; B-->5[\" is a 2005 musical fantasy film\"]; C-->6[\"When I heard `Wonka's welcome song`, so upset.\"]; C-->7[\"I'm still afraid this.\"]; subgraph storage A.md B.md C.md end subgraph localDatabase subgraph metadata A B C end subgraph chunks 1 2 3 4 5 6 7 end end Figure 1 A: Willy Wonka, Willy Wonka The amazing Chocolatier Willy Wonka, Willy Wonka Everybody give a cheer! B: Charlie and the Chocolate Factory is a 2005 musucal fantasy film C: When I heard `Wonka's welcome song`, so upset. I'm still afraid this. After we edit the files, the metadata is usually updated and a bit of new chunks are born. And if there already exists one made from the same contents, it will be shared. C: When I heard `Wonka's welcome song`, so upset. I'm still afraid the song that starts with this... Willy Wonka, Willy Wonka graph LR A.md-->A; B.md-->B; C.md-->C; A-->1[\"Willy Wonka, Willy Wonka\"]; A-->2[\"The amazing Chocolatier\"]; A-->1; A-->3[\"Everybody give a cheer!\"]; B-->4[\"Charlie and the Chocolate Factory\"]; B-->5[\" is a 2005 musical fantasy film\"]; C-->6[\"When I heard `Wonka's welcome song`, so upset.\"]; 7[\"I'm still afraid \"]; C-->8[\"I'm still afraid the song that starts with this...\"]; C-->1; subgraph storage A.md B.md C.md end subgraph localDatabase subgraph metadata A B C end subgraph chunks 1 2 3 4 5 6 7 8 end end Figure 2 (metadata C and chunk When I heard... will be transfered) Therefore, we can transfer only the metadata and some limited chunks and keep a low bandwidth and less traffic. That enables LiveSync . does not cool? As shown in Figure 2, old chunks that are not currently referenced will be left behind. So, although these chunks may one day be re-used, the database will continue to bloat. Due to this, At some point we must rebuild the database, and it is up to us to decide when to do so. We can count how many unrefferenced-chunks are retained by the command Check garbages now .","title":"What is the database?"},{"location":"What%20is%20the%20database/#what-is-the-database","text":"LiveSync does not synchronise files directly. All files are synchronised to the local database. At this time, files are separated into two or more entries; the metadata and chunks. We call this as differential replication (I have decided to write this document.) And them will be synchronised between each devices by replicating own local databases to the remote database. graph TB subgraph local[device_A] storage[Storage] <--> localDB[Database]; end subgraph anotherLocal[device_B] anotherStorage[Storage] <--> anotherLocalDB[Database]; end localDB <--> remoteDB[CouchDB]; anotherLocalDB <--> remoteDB; Chunks are key to low-traffic replication and synchronisation. Usually, editable text-file will be split by new-line-mark. ( Details and non-usual cases are here ) Chunks are keyed by its contents, and all metadata has a list of chunk keys as below. graph LR A.md-->A; B.md-->B; C.md-->C; A-->1[\"Willy Wonka, Willy Wonka\"]; A-->2[\"The amazing Chocolatier\"]; A-->1; A-->3[\"Everybody give a cheer!\"]; B-->4[\"Charlie and the Chocolate Factory\"]; B-->5[\" is a 2005 musical fantasy film\"]; C-->6[\"When I heard `Wonka's welcome song`, so upset.\"]; C-->7[\"I'm still afraid this.\"]; subgraph storage A.md B.md C.md end subgraph localDatabase subgraph metadata A B C end subgraph chunks 1 2 3 4 5 6 7 end end Figure 1 A: Willy Wonka, Willy Wonka The amazing Chocolatier Willy Wonka, Willy Wonka Everybody give a cheer! B: Charlie and the Chocolate Factory is a 2005 musucal fantasy film C: When I heard `Wonka's welcome song`, so upset. I'm still afraid this. After we edit the files, the metadata is usually updated and a bit of new chunks are born. And if there already exists one made from the same contents, it will be shared. C: When I heard `Wonka's welcome song`, so upset. I'm still afraid the song that starts with this... Willy Wonka, Willy Wonka graph LR A.md-->A; B.md-->B; C.md-->C; A-->1[\"Willy Wonka, Willy Wonka\"]; A-->2[\"The amazing Chocolatier\"]; A-->1; A-->3[\"Everybody give a cheer!\"]; B-->4[\"Charlie and the Chocolate Factory\"]; B-->5[\" is a 2005 musical fantasy film\"]; C-->6[\"When I heard `Wonka's welcome song`, so upset.\"]; 7[\"I'm still afraid \"]; C-->8[\"I'm still afraid the song that starts with this...\"]; C-->1; subgraph storage A.md B.md C.md end subgraph localDatabase subgraph metadata A B C end subgraph chunks 1 2 3 4 5 6 7 8 end end Figure 2 (metadata C and chunk When I heard... will be transfered) Therefore, we can transfer only the metadata and some limited chunks and keep a low bandwidth and less traffic. That enables LiveSync . does not cool? As shown in Figure 2, old chunks that are not currently referenced will be left behind. So, although these chunks may one day be re-used, the database will continue to bloat. Due to this, At some point we must rebuild the database, and it is up to us to decide when to do so. We can count how many unrefferenced-chunks are retained by the command Check garbages now .","title":"What is the database?"},{"location":"about-vrtmrz/","text":"About vorotamoroz \u00b6 Formerly a medical software engineer. Currently works for a machinery manufacturer, developing software and services for internal combustion engines and anything that uses them. I am not a hacker, but also not even that practical. Just I try to remain polite because of my rude nature. Japanese Registered Information Security Specialist. Twitter: @vorotamoroz (Tweeting daily life in Japanese.) I am not so well at English. But, I will try my best. Would you kindly contribute your corrections?","title":"About vorotamoroz"},{"location":"about-vrtmrz/#about-vorotamoroz","text":"Formerly a medical software engineer. Currently works for a machinery manufacturer, developing software and services for internal combustion engines and anything that uses them. I am not a hacker, but also not even that practical. Just I try to remain polite because of my rude nature. Japanese Registered Information Security Specialist. Twitter: @vorotamoroz (Tweeting daily life in Japanese.) I am not so well at English. But, I will try my best. Would you kindly contribute your corrections?","title":"About vorotamoroz"},{"location":"e2ee/","text":"End-to-end encryption \u00b6 If we want to use the server, that served as SaaS or as a tenant, we think we would love to keep the document secure more than in the case of using a dedicated server. Therefore, we can use end-to-end-encryption, to mitigate this risk of the accidents when somebody can see the disk or network intercommunication. You can enable End to End Encryption after you set Passphrase . Then, all content of the remote database will be encrypted automatically while in replication. Be careful, filenames and metadata will not be encrypted . The encryption algorithm is AES-GCM. If you noticed the failure of the algorithm, please inform me! How to change the passphrase? \u00b6 We must rebuild the remote database.","title":"End-to-end encryption"},{"location":"e2ee/#end-to-end-encryption","text":"If we want to use the server, that served as SaaS or as a tenant, we think we would love to keep the document secure more than in the case of using a dedicated server. Therefore, we can use end-to-end-encryption, to mitigate this risk of the accidents when somebody can see the disk or network intercommunication. You can enable End to End Encryption after you set Passphrase . Then, all content of the remote database will be encrypted automatically while in replication. Be careful, filenames and metadata will not be encrypted . The encryption algorithm is AES-GCM. If you noticed the failure of the algorithm, please inform me!","title":"End-to-end encryption"},{"location":"e2ee/#how-to-change-the-passphrase","text":"We must rebuild the remote database.","title":"How to change the passphrase?"},{"location":"histoy/","text":"We can see the editing history of the document in Show history . (only changes that happend on the device opened Show history ) And content can be copied to clipboard by Copy to clipboard , and take file back to the content on that point by Back to this revision . If we take the document back to the old revision, it will be saved as new revision with current timestamp to override other devices. Be careful, but we can take it back again and again. Note If you change the filename, the history will be lost. If we want to show about the file that we had deleted, we can find them to Pick a file to show history","title":"Histoy"},{"location":"index_/","text":"Obsidian Notes \u00b6 Publish your public notes with MkDocs Hello World! \u00b6 The index.md in the /docs folder is the homepage you see here. The folders in /docs appear as the main sections on the navigation bar. The notes appear as pages within these sections. For example, [[Note 1]] in Topic 1","title":"Obsidian Notes"},{"location":"index_/#obsidian-notes","text":"Publish your public notes with MkDocs","title":"Obsidian Notes"},{"location":"index_/#hello-world","text":"The index.md in the /docs folder is the homepage you see here. The folders in /docs appear as the main sections on the navigation bar. The notes appear as pages within these sections. For example, [[Note 1]] in Topic 1","title":"Hello World!"},{"location":"plugins/","text":"Plugin and setting synchronisation. \u00b6 Sync hidden files \u00b6 This feature is still experimental. I'm using this every day and getting better, less fragile. But still sometimes works ridiculous. Be sure to back your vault up to some rigid place. Sync hidden files \u00b6 If we enable this. LiveSync scans changes on hidden files. Changes in hidden files make no notification to LiveSync. So LiveSync must scan them in periodic or before replication once. Scan hidden files before replication \u00b6 If enabled, LiveSync scans for changes before each replication; Only works for non-LiveSync. Scan hidden files periodicaly. \u00b6 If set to non-zero value, LiveSync scans for changes each configured seconds. Skip patterns. \u00b6 List of regular expressions to skip files during scan and synchronisation. For synchronisation across platforms, .workspace$ must be added in addition to the default. What will happen? \u00b6 When new hidden files are incoming, popups will be shown. Enabled plug-in's files notification. If we press HERE , the plugin will be reloaded. Disabled plug-in's files or Obsidian's files file notification. If you press HERE , Obsidian will be reloaded. What can we do when we have applied the wrong changeset? \u00b6 Take it easy, chill down and open Pick file to show history . and type .obsidian/ or names that you have seen on the dialog. If you choose one of the files, open it. If the file had history of recently modified, we can roll the file back by Back to this revision . We should restart obsidian after roll it back. Plugins and their settings \u00b6 The older feature of the LiveSync. but works well if you want to pick and apply the plugins and their configuration.","title":"Plugin and setting synchronisation."},{"location":"plugins/#plugin-and-setting-synchronisation","text":"","title":"Plugin and setting synchronisation."},{"location":"plugins/#sync-hidden-files","text":"This feature is still experimental. I'm using this every day and getting better, less fragile. But still sometimes works ridiculous. Be sure to back your vault up to some rigid place.","title":"Sync hidden files"},{"location":"plugins/#sync-hidden-files_1","text":"If we enable this. LiveSync scans changes on hidden files. Changes in hidden files make no notification to LiveSync. So LiveSync must scan them in periodic or before replication once.","title":"Sync hidden files"},{"location":"plugins/#scan-hidden-files-before-replication","text":"If enabled, LiveSync scans for changes before each replication; Only works for non-LiveSync.","title":"Scan hidden files before replication"},{"location":"plugins/#scan-hidden-files-periodicaly","text":"If set to non-zero value, LiveSync scans for changes each configured seconds.","title":"Scan hidden files periodicaly."},{"location":"plugins/#skip-patterns","text":"List of regular expressions to skip files during scan and synchronisation. For synchronisation across platforms, .workspace$ must be added in addition to the default.","title":"Skip patterns."},{"location":"plugins/#what-will-happen","text":"When new hidden files are incoming, popups will be shown. Enabled plug-in's files notification. If we press HERE , the plugin will be reloaded. Disabled plug-in's files or Obsidian's files file notification. If you press HERE , Obsidian will be reloaded.","title":"What will happen?"},{"location":"plugins/#what-can-we-do-when-we-have-applied-the-wrong-changeset","text":"Take it easy, chill down and open Pick file to show history . and type .obsidian/ or names that you have seen on the dialog. If you choose one of the files, open it. If the file had history of recently modified, we can roll the file back by Back to this revision . We should restart obsidian after roll it back.","title":"What can we do when we have applied the wrong changeset?"},{"location":"plugins/#plugins-and-their-settings","text":"The older feature of the LiveSync. but works well if you want to pick and apply the plugins and their configuration.","title":"Plugins and their settings"}]}